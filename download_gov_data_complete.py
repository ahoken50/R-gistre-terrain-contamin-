#!/usr/bin/env python3
"""
Script pour t√©l√©charger le fichier GPKG COMPLET du registre des terrains contamin√©s
et filtrer uniquement les donn√©es de Val-d'Or
"""

import pandas as pd
import geopandas as gpd
import requests
import json
import zipfile
from io import BytesIO
from datetime import datetime
from pathlib import Path

# URL du fichier GPKG COMPLET (ZIP)
GPKG_ZIP_URL = "https://stqc380donopppdtce01.blob.core.windows.net/donnees-ouvertes/Repertoire_terrains_contamines/RepertoireTerrainsContamines.gpkg.zip"

# Fichiers de sortie
EXCEL_PATH = "Registre-des-terrains-contamines-Valdor.xlsx"
JSON_OUTPUT = "public/data/government-data.json"

# Filtres pour Val-d'Or
CITY_FILTERS = ["VAL-D'OR", "VALDOR", "VAL D'OR", "VAL D OR"]

def download_and_extract_gpkg(url):
    """T√©l√©charge le ZIP et extrait le GPKG"""
    print(f"üì• T√©l√©chargement du fichier ZIP complet...")
    print(f"üîó URL : {url}")
    print("‚è≥ Cela peut prendre quelques minutes (fichier de plusieurs Mo)...")
    
    resp = requests.get(url, timeout=600)
    resp.raise_for_status()
    
    print(f"‚úÖ T√©l√©charg√© : {len(resp.content) / (1024*1024):.2f} Mo")
    
    # Extraire le GPKG du ZIP
    print("üì¶ Extraction du fichier GPKG...")
    with zipfile.ZipFile(BytesIO(resp.content)) as z:
        # Trouver le fichier GPKG dans le ZIP
        gpkg_files = [f for f in z.namelist() if f.endswith('.gpkg')]
        if not gpkg_files:
            raise Exception("Aucun fichier GPKG trouv√© dans le ZIP")
        
        gpkg_filename = gpkg_files[0]
        print(f"üìÑ Fichier trouv√© : {gpkg_filename}")
        
        # Extraire en m√©moire
        gpkg_data = z.read(gpkg_filename)
        print(f"‚úÖ Extrait : {len(gpkg_data) / (1024*1024):.2f} Mo")
        
        return BytesIO(gpkg_data)

def filter_valdor_data(gdf):
    """Filtre les donn√©es pour Val-d'Or"""
    print(f"\nüîç Recherche des terrains de Val-d'Or...")
    print(f"üìä Total d'enregistrements dans le fichier : {len(gdf)}")
    
    # Chercher dans toutes les colonnes textuelles
    valdor_mask = pd.Series([False] * len(gdf))
    
    for filter_term in CITY_FILTERS:
        print(f"\n   Recherche de '{filter_term}'...")
        for col in gdf.columns:
            if gdf[col].dtype == 'object' and col != 'geometry':
                try:
                    mask = gdf[col].astype(str).str.upper().str.contains(
                        filter_term.replace("'", "").replace("-", "").replace(" ", ""),
                        na=False,
                        regex=False
                    )
                    if mask.any():
                        print(f"      ‚úì Trouv√© {mask.sum()} dans '{col}'")
                        valdor_mask = valdor_mask | mask
                except:
                    pass
    
    gdf_valdor = gdf[valdor_mask].drop_duplicates()
    
    if len(gdf_valdor) == 0:
        print(f"\n‚ö†Ô∏è  Aucun terrain trouv√© avec les filtres : {CITY_FILTERS}")
        print(f"üîç Recherche √©largie avec 'VAL'...")
        
        # Recherche plus large
        for col in gdf.columns:
            if gdf[col].dtype == 'object' and col != 'geometry':
                mask = gdf[col].astype(str).str.upper().str.contains('VAL', na=False)
                if mask.any():
                    print(f"   ‚úì Colonne '{col}' contient {mask.sum()} enregistrements avec 'VAL'")
                    print(f"      Exemples : {gdf[mask][col].unique()[:3]}")
    
    return gdf_valdor

def main():
    print("="*80)
    print("üîÑ T√âL√âCHARGEMENT COMPLET DES DONN√âES GOUVERNEMENTALES")
    print("="*80)
    print(f"‚è∞ D√©but : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    try:
        # T√©l√©charger et extraire le GPKG
        gpkg_data = download_and_extract_gpkg(GPKG_ZIP_URL)
        
        # Lire le fichier GPKG
        print("\nüìÇ Lecture du fichier GPKG...")
        gdf = gpd.read_file(gpkg_data, layer=0)
        
        print(f"‚úÖ Fichier charg√© : {len(gdf)} enregistrements au total")
        
        # Afficher les colonnes
        print("\nüìã Colonnes disponibles :")
        for i, col in enumerate(gdf.columns, 1):
            print(f"  {i:2d}. {col}")
        
        # Filtrer pour Val-d'Or
        gdf_valdor = filter_valdor_data(gdf)
        
        if len(gdf_valdor) == 0:
            print("\n‚ùå Aucune donn√©e trouv√©e pour Val-d'Or")
            print("üí° Utilisation de toutes les donn√©es pour d√©monstration")
            gdf_valdor = gdf
        else:
            print(f"\n‚úÖ {len(gdf_valdor)} terrains trouv√©s pour Val-d'Or")
        
        # Supprimer la g√©om√©trie pour la conversion
        df_result = pd.DataFrame(gdf_valdor)
        if 'geometry' in df_result.columns:
            df_result = df_result.drop(columns=['geometry'])
        
        # Sauvegarder en Excel
        print(f"\nüíæ Sauvegarde Excel : {EXCEL_PATH}")
        df_result.to_excel(EXCEL_PATH, index=False)
        print(f"‚úÖ Excel cr√©√© : {EXCEL_PATH}")
        
        # Convertir en JSON
        print(f"\nüîÑ Conversion en JSON...")
        
        # Convertir les dates
        for col in df_result.columns:
            if df_result[col].dtype == 'datetime64[ns]':
                df_result[col] = df_result[col].dt.strftime('%Y-%m-%d')
        
        # Remplacer NaN
        df_result = df_result.fillna('')
        
        # Convertir en dict
        data = df_result.to_dict(orient='records')
        
        # Cr√©er le dossier
        Path(JSON_OUTPUT).parent.mkdir(parents=True, exist_ok=True)
        
        # Cr√©er le JSON
        output_data = {
            'data': data,
            'metadata': {
                'source': 'Registre des terrains contamin√©s - Gouvernement du Qu√©bec',
                'source_url': GPKG_ZIP_URL,
                'city': 'Val-d\'Or',
                'total_records_in_file': len(gdf),
                'valdor_records': len(gdf_valdor),
                'last_update': datetime.now().isoformat(),
                'generated_by': 'download_gov_data_complete.py',
                'columns': list(df_result.columns)
            }
        }
        
        # Sauvegarder
        with open(JSON_OUTPUT, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ JSON cr√©√© : {JSON_OUTPUT}")
        print(f"üìä {len(data)} enregistrements export√©s")
        
        # Aper√ßu
        if len(data) > 0:
            print("\nüìÑ Aper√ßu (premier enregistrement) :")
            print(json.dumps(data[0], indent=2, ensure_ascii=False))
        
        print("\n" + "="*80)
        print("‚úÖ TRAITEMENT TERMIN√â AVEC SUCC√àS")
        print("="*80)
        print(f"‚è∞ Fin : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"\nüìä R√©sum√© :")
        print(f"   - Total d'enregistrements dans le fichier : {len(gdf)}")
        print(f"   - Enregistrements pour Val-d'Or : {len(gdf_valdor)}")
        print(f"   - Fichier Excel : {EXCEL_PATH}")
        print(f"   - Fichier JSON : {JSON_OUTPUT}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå Erreur : {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
